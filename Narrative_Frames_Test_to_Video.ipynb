{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installing Dependencies"
      ],
      "metadata": {
        "id": "0SnIHGnJxkzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────────────────────\n",
        "# Cell 1: Install all dependencies\n",
        "# ───────────────────────────────────────────────────────────────────────────────\n",
        "!pip install -q spacy diffusers accelerate safetensors ffmpeg-python moviepy gtts soundfile pydub git+https://github.com/coqui-ai/TTS.git\n",
        "!python -m spacy download en_core_web_sm\n",
        "!apt-get update -qq && apt-get install -y git-lfs ffmpeg libsndfile1 espeak-ng\n",
        "!git-lfs install\n",
        "!git clone https://huggingface.co/ByteDance/AnimateDiff-Lightning /content/AnimateDiff-Lightning\n",
        "!pip install pyngrok\n",
        "!pip install streamlit-lottie\n",
        "!pip install streamlit-extras\n",
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pmp7ARKbl9mc",
        "outputId": "d547ac31-ce58-4d9d-e223-2ae3d122726e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.0/837.0 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for TTS (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "nx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\n",
            "xarray 2025.3.1 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.3 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsndfile1 is already the newest version (1.0.31-2ubuntu0.2).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
            "The following additional packages will be installed:\n",
            "  espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "The following NEW packages will be installed:\n",
            "  espeak-ng espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n",
            "0 upgraded, 5 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 4,526 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpcaudio0 amd64 1.1-6build2 [8,956 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsonic0 amd64 0.2.0-11build1 [10.3 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 espeak-ng-data amd64 1.50+dfsg-10ubuntu0.1 [3,956 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libespeak-ng1 amd64 1.50+dfsg-10ubuntu0.1 [207 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 espeak-ng amd64 1.50+dfsg-10ubuntu0.1 [343 kB]\n",
            "Fetched 4,526 kB in 2s (2,757 kB/s)\n",
            "Selecting previously unselected package libpcaudio0:amd64.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../libpcaudio0_1.1-6build2_amd64.deb ...\n",
            "Unpacking libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "Preparing to unpack .../libsonic0_0.2.0-11build1_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Selecting previously unselected package espeak-ng-data:amd64.\n",
            "Preparing to unpack .../espeak-ng-data_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package libespeak-ng1:amd64.\n",
            "Preparing to unpack .../libespeak-ng1_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Selecting previously unselected package espeak-ng.\n",
            "Preparing to unpack .../espeak-ng_1.50+dfsg-10ubuntu0.1_amd64.deb ...\n",
            "Unpacking espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libpcaudio0:amd64 (1.1-6build2) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-11build1) ...\n",
            "Setting up espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\n",
            "Setting up espeak-ng (1.50+dfsg-10ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Git LFS initialized.\n",
            "Cloning into '/content/AnimateDiff-Lightning'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 88 (delta 40), reused 88 (delta 40), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (88/88), 738.36 KiB | 9.84 MiB/s, done.\n",
            "Filtering content: 100% (11/11), 6.78 GiB | 39.74 MiB/s, done.\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.7-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.7-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "p-SaXntBxr5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing"
      ],
      "metadata": {
        "id": "jEdkPqRqxsz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────────────────────\n",
        "# Cell 2: preprocessing.py\n",
        "# ───────────────────────────────────────────────────────────────────────────────\n",
        "%%bash\n",
        "cat << 'EOF' > preprocessing.py\n",
        "import re\n",
        "import spacy\n",
        "from typing import List\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def clear_context_only(text: str,\n",
        "                       pronouns: tuple = (\"he\",\"him\",\"his\",\"she\",\"her\")) -> List[str]:\n",
        "    \"\"\"\n",
        "    1. Strip UI artifacts/numbering lines.\n",
        "    2. Find main NP in first real sentence.\n",
        "    3. Replace all pronouns → that NP.\n",
        "    4. Split, dedupe & return sentences.\n",
        "     \"\"\"\n",
        "    lines = []\n",
        "    for line in text.splitlines():\n",
        "        line = line.strip()\n",
        "        if not line or line.startswith(\"----\") or re.match(r\"^\\d+\\.($|\\s)\", line):\n",
        "            continue\n",
        "        lines.append(line)\n",
        "    cleaned = \" \".join(lines)\n",
        "\n",
        "    doc = nlp(cleaned)\n",
        "    try:\n",
        "        first_sent = list(doc.sents)[0]\n",
        "        antecedent = next(first_sent.noun_chunks).text.strip()\n",
        "    except Exception:\n",
        "        raise ValueError(\"No noun phrase found in first sentence.\")\n",
        "\n",
        "    def _rep(m):\n",
        "        p = m.group(0).lower()\n",
        "        return antecedent + (\"'s\" if p==\"his\" else \"\") if p in pronouns else m.group(0)\n",
        "\n",
        "    pattern = r\"\\b(\" + \"|\".join(pronouns) + r\")\\b\"\n",
        "    resolved = re.sub(pattern, _rep, cleaned, flags=re.IGNORECASE)\n",
        "\n",
        "    sents = [s.strip()+'.' for s in resolved.split('.') if s.strip() and not re.match(r\"^\\d+\\.?$\", s)]\n",
        "    # dedupe\n",
        "    seen = set(); out = []\n",
        "    for s in sents:\n",
        "        k = s.lower()\n",
        "        if k not in seen:\n",
        "            seen.add(k); out.append(s)\n",
        "    return out\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "EFenmWcLl_Ib"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model Utils"
      ],
      "metadata": {
        "id": "8GWH4opKxxQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────────────────────\n",
        "# Cell 3: model.py\n",
        "# ───────────────────────────────────────────────────────────────────────────────\n",
        "%%bash\n",
        "cat << 'EOF' > model.py\n",
        "import os, torch, numpy as np\n",
        "from safetensors.torch import load_file\n",
        "from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
        "from PIL import Image\n",
        "import ffmpeg\n",
        "import tempfile\n",
        "\n",
        "def load_pipeline(adapter_path=\"/content/AnimateDiff-Lightning\"):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    dtype = torch.float16 if device==\"cuda\" else torch.float32\n",
        "    step = 4\n",
        "\n",
        "    ckpt = os.path.join(adapter_path, f\"animatediff_lightning_{step}step_diffusers.safetensors\")\n",
        "    adapter = MotionAdapter().to(device, dtype)\n",
        "    adapter.load_state_dict(load_file(ckpt, device=device))\n",
        "\n",
        "    base = \"emilianJR/epiCRealism\"\n",
        "    pipe = AnimateDiffPipeline.from_pretrained(base, motion_adapter=adapter, torch_dtype=dtype).to(device)\n",
        "    pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\", beta_schedule=\"linear\")\n",
        "    pipe.enable_model_cpu_offload(); pipe.enable_attention_slicing()\n",
        "    return pipe, step\n",
        "\n",
        "def frames_to_video(frames, fps, out_path):\n",
        "    with tempfile.TemporaryDirectory() as td:\n",
        "        for i, f in enumerate(frames):\n",
        "            Image.fromarray(f).save(f\"{td}/frame_{i:05d}.png\")\n",
        "        (\n",
        "            ffmpeg\n",
        "            .input(f\"{td}/frame_%05d.png\", framerate=fps)\n",
        "            .output(out_path, pix_fmt=\"yuv420p\", vcodec=\"libx264\")\n",
        "            .overwrite_output().run(quiet=True)\n",
        "        )\n",
        "\n",
        "def generate_segments(pipe, step, prompts, fps=6):\n",
        "    segs = []\n",
        "    for idx, p in enumerate(prompts):\n",
        "        print(f\"→ Generating segment {idx+1}/{len(prompts)}\")\n",
        "        out = pipe(prompt=p, guidance_scale=1.0, num_inference_steps=step)\n",
        "        frames = [np.array(f) for f in out.frames[0]]\n",
        "        vid = f\"seg_{idx}.mp4\"\n",
        "        frames_to_video(frames, fps, vid)\n",
        "        segs.append((vid, p))\n",
        "        torch.cuda.empty_cache()\n",
        "    return segs\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "EiqPHUo2mDz2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Audio Generating"
      ],
      "metadata": {
        "id": "XnAnxRJ7x5bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat << 'EOF' > audio.py\n",
        "import os, tempfile, re\n",
        "from TTS.api import TTS\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Regex to split on sentence boundaries\n",
        "_SENT_RE = re.compile(r'(?<=[\\\\.\\\\!?]) +')\n",
        "\n",
        "# Pre-defined models you can choose from:\n",
        "AVAILABLE_MODELS = {\n",
        "    \"LJSpeech VITS\":         \"tts_models/en/ljspeech/vits\",\n",
        "    \"Tacotron2-DDC\":         \"tts_models/en/ljspeech/tacotron2-DDC\",\n",
        "    \"VCTK VITS\":             \"tts_models/en/vctk/vits\",\n",
        "    # Add more model keys ↔ HF IDs here…\n",
        "}\n",
        "\n",
        "def list_available_models():\n",
        "    \"\"\"Return human-readable model names.\"\"\"\n",
        "    return list(AVAILABLE_MODELS.keys())\n",
        "\n",
        "def generate_audio(\n",
        "    text: str,\n",
        "    model_key: str = \"LJSpeech VITS\",\n",
        "    speaker: str = None,\n",
        "    language: str = None\n",
        ") -> (str, list):\n",
        "    \"\"\"\n",
        "    Generate speech for the given text.\n",
        "\n",
        "    Args:\n",
        "      text: full input text.\n",
        "      model_key: key from AVAILABLE_MODELS.\n",
        "      speaker: optional (for multi-speaker models).\n",
        "      language: optional (for multilingual models).\n",
        "\n",
        "    Returns:\n",
        "      final_wav: path to the concatenated WAV file.\n",
        "      timeline: list of (sentence, start_time, duration).\n",
        "    \"\"\"\n",
        "    if model_key not in AVAILABLE_MODELS:\n",
        "        raise ValueError(f\"Unknown model '{model_key}'. Choose from {list_available_models()}\")\n",
        "\n",
        "    model_name = AVAILABLE_MODELS[model_key]\n",
        "    tmpdir = tempfile.mkdtemp()\n",
        "\n",
        "    # Split text into sentences\n",
        "    sentences = _SENT_RE.split(text.strip())\n",
        "    if not sentences:\n",
        "        raise ValueError(\"No valid sentences found in text.\")\n",
        "\n",
        "    # Initialize TTS engine (no speaker/language here)\n",
        "    tts = TTS(model_name=model_name)\n",
        "\n",
        "    segs, timeline, current = [], [], 0.0\n",
        "    for i, sent in enumerate(sentences, 1):\n",
        "        out_path = os.path.join(tmpdir, f\"seg_{i}.wav\")\n",
        "        # Pass speaker/language to tts_to_file\n",
        "        tts.tts_to_file(text=sent, file_path=out_path,\n",
        "                        speaker=speaker, language=language)\n",
        "        data, sr = sf.read(out_path)\n",
        "        dur = len(data) / sr\n",
        "\n",
        "        segs.append(AudioSegment.from_wav(out_path))\n",
        "        timeline.append((sent, current, dur))\n",
        "        current += dur\n",
        "\n",
        "    # Concatenate segments\n",
        "    final_wav = os.path.join(tmpdir, \"output.wav\")\n",
        "    combined = segs[0]\n",
        "    for seg in segs[1:]:\n",
        "        combined += seg\n",
        "    combined.export(final_wav, format=\"wav\")\n",
        "\n",
        "    return final_wav, timeline\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "mwD4HsEfx9wC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Streamlit UI"
      ],
      "metadata": {
        "id": "YODAYZiOx-nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat << 'EOF' > streamlit_app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "\n",
        "# Session state to manage page navigation\n",
        "if \"page\" not in st.session_state:\n",
        "    st.session_state.page = \"home\"\n",
        "\n",
        "def go_to_creator():\n",
        "    st.session_state.page = \"creator\"\n",
        "\n",
        "if st.session_state.page == \"home\":\n",
        "    st.set_page_config(page_title=\"🎬 Narrative Frames\", layout=\"centered\")\n",
        "    st.title(\"🎬 Narrative Frames\")\n",
        "    st.markdown(\"#### Transform your text into compelling video stories.\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    **Narrative Frames** is an AI-powered text-to-video storytelling platform.\n",
        "    Just enter a story, and we generate beautiful animated visuals, synced with lifelike narration.\n",
        "    Perfect for educators, creators, and storytellers!\n",
        "    \"\"\")\n",
        "\n",
        "    st.divider()\n",
        "    st.subheader(\"👨‍💻 Meet the Team\")\n",
        "\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    with col1:\n",
        "        st.image(\"/content/drive/MyDrive/Narrative_Frames/Vinit_jethwa.jpeg\", caption=\"\", use_container_width=True)\n",
        "        st.markdown('<div style=\"text-align: center;\"><strong>Vinit Jethwa</strong></div>', unsafe_allow_html=True)\n",
        "\n",
        "    with col2:\n",
        "        st.image(\"/content/drive/MyDrive/Narrative_Frames/sachin_singh.jpeg\", caption=\"\", use_container_width=True)\n",
        "        st.markdown('<div style=\"text-align: center;\"><strong>Sachin Singh</strong></div>', unsafe_allow_html=True)\n",
        "\n",
        "    with col3:\n",
        "        st.image(\"/content/drive/MyDrive/Narrative_Frames/kaif_qureshi.jpeg\", caption=\"\", use_container_width=True)\n",
        "        st.markdown('<div style=\"text-align: center;\"><strong>Kaif Qureshi</strong></div>', unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "    st.divider()\n",
        "    st.markdown(\"### 🚀 Ready to create your story?\")\n",
        "    if st.button(\"Start\", key=\"start_button\"):\n",
        "        go_to_creator()\n",
        "\n",
        "elif st.session_state.page == \"creator\":\n",
        "    from video_creator import show_video_creator_ui\n",
        "    show_video_creator_ui()\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "EtTqmdNzcE8r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat << 'EOF' > video_creator.py\n",
        "\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "from preprocessing import clear_context_only\n",
        "from model import load_pipeline, generate_segments\n",
        "from audio import generate_audio, list_available_models\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips, AudioFileClip\n",
        "\n",
        "def show_video_creator_ui():\n",
        "    st.title(\"🎬 NarrativeFrames: Create Your Story Video\")\n",
        "\n",
        "    # Voice model selection\n",
        "    model_choice = st.selectbox(\"🎙️ Choose Voice Model\", list_available_models())\n",
        "\n",
        "    # Story input\n",
        "    story = st.text_area(\"📝 Enter your story:\", height=200)\n",
        "\n",
        "    if st.button(\"🚀 Start Generating\"):\n",
        "        if not story.strip():\n",
        "            st.warning(\"⚠️ Please enter a story.\")\n",
        "            return\n",
        "\n",
        "        # Preprocessing\n",
        "        st.info(\"🔍 Extracting prompts...\")\n",
        "        prompts = clear_context_only(story)\n",
        "        for i, p in enumerate(prompts):\n",
        "            st.markdown(f\"**{i+1}.** {p}\")\n",
        "\n",
        "        # Load animation model\n",
        "        st.info(\"⏳ Loading animation pipeline...\")\n",
        "        pipe, step = load_pipeline()\n",
        "        st.success(\"✅ Model loaded.\")\n",
        "\n",
        "        segments = []\n",
        "\n",
        "        # Generate segments\n",
        "        for i, prompt in enumerate(prompts):\n",
        "            st.markdown(f\"### 🎞️ Segment {i+1}\")\n",
        "            st.text(f\"Processing:\\n{prompt}\")\n",
        "\n",
        "            # Generate video\n",
        "            vid_path, _ = generate_segments(pipe, step, [prompt])[0]\n",
        "\n",
        "            # Generate audio\n",
        "            audio_path, _ = generate_audio(prompt, model_key=model_choice)\n",
        "\n",
        "            # Merge video and audio\n",
        "            merged = f\"merged_{i}.mp4\"\n",
        "            vc = VideoFileClip(vid_path)\n",
        "            ac = AudioFileClip(audio_path)\n",
        "            final = vc.set_audio(ac)\n",
        "            final.write_videofile(merged, fps=vc.fps, codec=\"libx264\", audio_codec=\"aac\", verbose=False, logger=None)\n",
        "            segments.append(merged)\n",
        "\n",
        "        # Concatenate all segments\n",
        "        st.info(\"🎞️ Concatenating all segments...\")\n",
        "        clips = [VideoFileClip(p) for p in segments]\n",
        "        out = \"final_story.mp4\"\n",
        "        final_video = concatenate_videoclips(clips, method=\"compose\")\n",
        "        final_video.write_videofile(out, fps=clips[0].fps, codec=\"libx264\", audio_codec=\"aac\", verbose=False, logger=None)\n",
        "\n",
        "        # Show results\n",
        "        st.success(\"✅ Done! Your video is ready.\")\n",
        "        st.video(out)\n",
        "        with open(out, \"rb\") as f:\n",
        "            st.download_button(\"⬇️ Download Final Video\", data=f, file_name=\"final_story.mp4\", mime=\"video/mp4\")\n",
        "\n",
        "        # Cleanup\n",
        "        for path in segments:\n",
        "            os.remove(path)\n",
        "\n",
        "# EOF\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj9BDpdSUduN",
        "outputId": "48f13fc4-a4f1-43b4-d311-c44cb372f79f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bash: line 74: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h6C64lhdyGV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Deployment : on Local host"
      ],
      "metadata": {
        "id": "_Xa3tcBfyG-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Streamlit & pyngrok, then verify Streamlit is installed\n",
        "!pip install -q streamlit pyngrok\n",
        "\n",
        "# Check that import works and print version\n",
        "!python3 -c \"import streamlit; print('✅ Streamlit version:', streamlit.__version__)\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab6MJtORtrku",
        "outputId": "df948de9-c74b-4c56-a042-c7c46bd4a748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Streamlit version: 1.45.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, socket\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# 1) Kill any old Streamlit processes & tunnels\n",
        "os.system(\"pkill -f streamlit || true\")\n",
        "ngrok.kill()\n",
        "\n",
        "# 2) Launch updated Streamlit app\n",
        "get_ipython().system_raw(\n",
        "    \"streamlit run streamlit_app.py \"\n",
        "    \"--server.port 8501 --server.enableCORS false \"\n",
        "    \"> /content/streamlit.log 2>&1 &\"\n",
        ")\n",
        "\n",
        "# 3) Wait for Streamlit to boot\n",
        "time.sleep(20)\n",
        "\n",
        "# 4) Print logs for debugging\n",
        "print(\"---- streamlit.log (first 20 lines) ----\")\n",
        "!head -n 20 /content/streamlit.log\n",
        "\n",
        "# 5) Port availability check\n",
        "def is_listening(port):\n",
        "    try:\n",
        "        with socket.create_connection((\"127.0.0.1\", port), timeout=5):\n",
        "            return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "print(f\"🔍 Listening on port 8501? → {is_listening(8501)}\")\n",
        "\n",
        "# 6) Create ngrok tunnel if Streamlit is up\n",
        "if is_listening(8501):\n",
        "    NGROK_AUTH_TOKEN = \"<YOUR_NGROK_TOKEN>\"\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    url = ngrok.connect(8501, \"http\")\n",
        "    print(\"🔗 Your Narrative Frames app is live at:\", url)\n",
        "else:\n",
        "    print(\"❌ Streamlit app failed to launch. Check the log above.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAK3tGEYzQ_v",
        "outputId": "85c6e750-fc57-497a-ca13-1ce9eeba00a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- streamlit.log (first 20 lines) ----\n",
            "2025-05-08 19:51:28.272 \n",
            "Warning: the config option 'server.enableCORS=false' is not compatible with\n",
            "'server.enableXsrfProtection=true'.\n",
            "As a result, 'server.enableCORS' is being overridden to 'true'.\n",
            "\n",
            "More information:\n",
            "In order to protect against CSRF attacks, we send a cookie with each request.\n",
            "To do so, we must specify allowable origins, which places a restriction on\n",
            "cross-origin resource sharing.\n",
            "\n",
            "If cross origin resource sharing is required, please disable server.enableXsrfProtection.\n",
            "            \n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Local URL: http://localhost:8501\n",
            "  Network URL: http://172.28.0.12:8501\n",
            "🔍 Listening on port 8501? → True\n",
            "🔗 Your Narrative Frames app is live at: NgrokTunnel: \"https://21c5-35-230-14-7.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ya6YlEqmdKRf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQajCKleaK22"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}